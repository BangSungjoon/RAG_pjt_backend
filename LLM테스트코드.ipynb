{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7N_qbxNK6O62"
      },
      "outputs": [],
      "source": [
        "pip install langchain openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cDMa9wR6iCX"
      },
      "outputs": [],
      "source": [
        "pip install langchain-community\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lh4msXv-8JCI"
      },
      "outputs": [],
      "source": [
        "# pinecone 설치\n",
        "!pip install pinecone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HeQhPy3-swy"
      },
      "outputs": [],
      "source": [
        "pip install kiwipiepy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVyX0518-0fb"
      },
      "outputs": [],
      "source": [
        "pip install langchain-upstage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdYCWEB76IZz"
      },
      "outputs": [],
      "source": [
        "import langchain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "from kiwipiepy import Kiwi\n",
        "from pinecone import Pinecone\n",
        "from langchain_upstage import UpstageEmbeddings\n",
        "import json\n",
        "\n",
        "# Pinecone Index 이름\n",
        "index_name = \"kb-docs\"  # 기존에 생성된 Index 이름\n",
        "\n",
        "# Pinecone 초기화\n",
        "pc = Pinecone(api_key=\"\")\n",
        "index = pc.Index(index_name)  # 기존 Index 가져오기\n",
        "\n",
        "\n",
        "# OpenAI API 키 설정\n",
        "api_key = \"\"\n",
        "\n",
        "# LangChain의 OpenAI LLM 설정\n",
        "chat = ChatOpenAI(\n",
        "    model=\"gpt-4o\",  # 또는 \"gpt-4o\"\n",
        "    openai_api_key=api_key,\n",
        "    temperature=0.7,\n",
        "    max_tokens=1000\n",
        ")\n",
        "\n",
        "\n",
        "query_text = input(\"\")\n",
        "kiwi = Kiwi()\n",
        "keywords = [token.form for token in kiwi.tokenize(query_text) if token.tag in ['NNG', 'NNP']]  # 일반 명사와 고유 명사 추출\n",
        "\n",
        "# 기본 file_detail 값 생성\n",
        "file_detail_values = []\n",
        "\n",
        "# 조건에 따라 file_detail 값 추가\n",
        "if \"대출\" in keywords or \"융자\" in keywords or \"자금\" in keywords:\n",
        "    file_detail_values.extend([\"담보대출\", \"자동차대출\", \"신용대출\"])\n",
        "if \"예금\" in keywords or \"저축\" in keywords or \"예치\" in keywords:\n",
        "    file_detail_values.append(\"예금\")\n",
        "if \"적금\" in keywords or \"정기적금\" in keywords or \"월저축\" in keywords:\n",
        "    file_detail_values.append(\"적금\")\n",
        "if \"통장\" in keywords or \"계좌\" in keywords or \"입출금\" in keywords:\n",
        "    file_detail_values.append(\"입출금자유\")\n",
        "if \"주택\" in keywords or \"집\" in keywords or \"부동산\" in keywords:\n",
        "    file_detail_values.append(\"담보대출\")\n",
        "if \"차\" in keywords or \"자동차\" in keywords or \"차량\" in keywords:\n",
        "    file_detail_values.append(\"자동차대출\")\n",
        "\n",
        "# OR 조건으로 필터 생성\n",
        "metadata_filter = {\n",
        "    \"file_detail\": {\"$in\": file_detail_values}  # file_detail이 리스트 중 하나에 포함\n",
        "}\n",
        "\n",
        "# Solar-Embedding 모델 로드\n",
        "embedding_model = UpstageEmbeddings(\n",
        "    model=\"solar-embedding-1-large\",\n",
        "    api_key=\"\"  # API 키를 여기에 입력하세요.\n",
        ")\n",
        "# Solar-Embedding으로 쿼리 텍스트를 벡터화\n",
        "query_vector = embedding_model.embed_query(query_text)\n",
        "\n",
        "# Pinecone에서 쿼리 실행\n",
        "namespace = \"kb_namespace\"  # 검색할 namespace 설정\n",
        "results = index.query(\n",
        "    vector=query_vector,     # 쿼리 벡터\n",
        "    namespace=namespace,     # 검색할 namespace\n",
        "    top_k=8,                 # 검색 결과 개수\n",
        "    include_values=False,    # 벡터 값 포함 여부\n",
        "    include_metadata=True,    # 메타데이터 포함 여부\n",
        "    filter=metadata_filter  # 메타메이터 필터 on\n",
        ")\n",
        "\n",
        "# 데이터 가공 및 병합\n",
        "grouped_data = {}\n",
        "\n",
        "for match in results[\"matches\"]:\n",
        "    file_name = match[\"metadata\"].get(\"file_name\", \"\")  # 파일 이름\n",
        "    file_detail = match[\"metadata\"].get(\"file_detail\", \"\")  # 파일 상세\n",
        "    file_text = match[\"metadata\"].get(\"text\", \"\")  # 파일 내용\n",
        "\n",
        "    # 같은 file_name 그룹화\n",
        "    if file_name not in grouped_data:\n",
        "        grouped_data[file_name] = {\"file_detail\": file_detail, \"texts\": []}\n",
        "    grouped_data[file_name][\"texts\"].append(file_text)\n",
        "\n",
        "# 데이터 확인\n",
        "for file_name, data in grouped_data.items():\n",
        "    print(f\"File Name: {file_name}\")\n",
        "    print(f\"Category: {data['file_detail']}\")\n",
        "    print(\"Contents:\")\n",
        "    for text in data[\"texts\"]:\n",
        "        print(f\"- {text[:100]}...\")  # 첫 100자만 출력\n",
        "    print(\"\\n\")\n",
        "\n",
        "# 메시지 정의\n",
        "system_message = SystemMessage(content=f\"\"\"\n",
        "You are an assistant for question-answering tasks specialized in financial products.\n",
        "You will be given JSON DATA and user conversation history.\n",
        "\n",
        "Structure of JSON DATA will be\n",
        "\n",
        "  Product Name:\n",
        "  Category:\n",
        "  Description:\n",
        "\n",
        "JSON DATA: {grouped_data}\n",
        "user conversation history :\n",
        "\n",
        "\n",
        "You must follow the rules below.\n",
        "\n",
        "1. Each file name represents the product name.\n",
        "2. The category indicates the type of product.\n",
        "3. Only use JSON DATA to find relevant product information.\n",
        "4. Do not mix content between different products.\n",
        "5. If the product cannot be identified, respond with: \"죄송합니다. 해당 상품 정보를 찾을 수 없습니다.\"\n",
        "6. If the input is unrelated to financial product consultations, respond with: \"저는 KB 국민은행의 금융 상품과 정보만 제공해드릴 수 있습니다. 다시 입력해주세요.\"\n",
        "7. If the input concerns financial institutions other than KB 국민은행, respond with: \"저는 KB 국민은행의 금융 상품과 정보만 제공해드릴 수 있습니다. 다시 입력해주세요.\"\n",
        "8. Answer naturally without including \"Product Name\", \"Category\", or \"Description\" in the response.\n",
        "9. Base your responses only on the product information and user conversation history.\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "# 사용자 질문\n",
        "human_message = HumanMessage(content=query_text)\n",
        "\n",
        "# LangChain LLM 호출\n",
        "response = chat([system_message, human_message])\n",
        "\n",
        "# 응답 출력\n",
        "print(response.content)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
